from selenium import webdriver
from selenium.webdriver.support.ui import Select
from time import sleep
import lxml.html
import requests
# create phantomjs object
driver = webdriver.PhantomJS()

# get target page object
driver.get('https://technet.microsoft.com/en-us/security/bulletins.aspx')

# get id of the select tag
select = Select(driver.find_element_by_id('productDropdown'))
select.select_by_value('10378')

#print(driver.page_source.split('\n'))

# wait for transition completion
#sleep(3)

#driver.save_screenshot('test.png')

# WebElement type
#print(type(driver.find_element_by_id('searchResults')))

# list type
#print(type(driver.find_elements_by_css_selector('tbody')))
#print(type(driver.find_elements_by_css_selector('tr')))

#print(type(driver))

# get parent element
parent_element = driver.find_element_by_id('searchResults')

for element in parent_element.find_elements_by_css_selector('tr'):
    print(element.text.replace(' ', ','))   

# memo
# get detail urls 
root = lxml.html.fromstring(driver.page_source)
urls_arr = []
for a in root.cssselect('#searchResults tr td a'):
    urls_arr.append(a.get('href'))



print(urls_arr)

# memo
response = requests.get(urls_arr[0])
#print(response.text)

# memo
# scrape detail page and return value what I want 
def scrape_detail_page(response):
    root = lxml.html.fromstring(response.content)
    
    # make data with dictionary
    affected_product = {
       'product': root.cssselect('#id_name tag tag tag')
       #'url': response.url
    }

    return affected_product



