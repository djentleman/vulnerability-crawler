import requests


def main():

    content = fetch()
    formatted = scrape(content)

    # write to file
    open('rhel_table_data.csv', 'w+').write(formatted)


def fetch():

    # get html object(text) with split(\n)
    content = requests.get('https://rhn.redhat.com/errata/rhel-server-6-errata.html').text.split('\n')
    return content


def scrape(content):

    # grep errataTableData
    data_def = ''
    for line in content:
        if 'errataTableData' in line:
            data_def = line
            break

    # generate a char array from the HTML
    char_arr = []
    prev = ''
    write_to_arr = False
    
    # ignore 
    for char in data_def:
        if write_to_arr:
            char_arr.append(char)
        if char == '[' and prev == '[':
            write_to_arr = True
        if char == ']' and prev == ']':
            write_to_arr = False
        prev = char

    # re-join blocks at beginning of the char_arr
    data_str = '[[' + ''.join(char_arr)

    # clean up the data so it's in a csv with every line containing a row
    formatted = data_str.replace('],[', ']\n[')\
                        .replace(']', '')\
                        .replace('[', '')
    
    return formatted

# __name__: module name
# __main__: module name is named by __main__ when the python script execute directly
# if this module is called by other module by import statement, the main() does not execute
if __name__ == '__main__':
    main()


